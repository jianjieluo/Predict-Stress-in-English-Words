{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献：\n",
    "pickle使用: http://www.cnblogs.com/pzxbc/archive/2012/03/18/2404715.html\n",
    "\n",
    "sklearn: http://www.cnblogs.com/jasonfreak/p/5448462.html\n",
    "\n",
    "数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 特征工程学习用例\n",
    "\n",
    "\n",
    "使用sklearn中的IRIS（鸢尾花）数据集来对特征处理功能进行说明。IRIS数据集由Fisher在1936年整理，包含4个特征（Sepal.Length（花萼长度）、Sepal.Width（花萼宽度）、Petal.Length（花瓣长度）、Petal.Width（花瓣宽度）），特征值都为正浮点数，单位为厘米。目标值为鸢尾花的分类（Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），Iris Virginica（维吉尼亚鸢尾））。导入IRIS数据集的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L0范数是指向量中非0的元素的个数。\n",
    "\n",
    "L1范数是指向量中各个元素绝对值之和\n",
    "\n",
    "L2范数是指向量各元素的平方和然后求平方根"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 预处理学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化，返回值为标准化后的数据\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "StandardScaler().fit_transform(iris.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#区间缩放，返回值为缩放到[0, 1]区间的数据\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MinMaxScaler().fit_transform(iris.data)；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化与归一化的区别\n",
    "\n",
    "　　简单来说，标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下。归一化是依照特征矩阵的行处理数据，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”。规则为l2的归一化公式如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#归一化，返回值为归一化后的数据\n",
    "from sklearn.preprocessing import Normalizer\n",
    "Normalizer().fit_transform(iris.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,   5.1 ,   3.5 , ...,   1.96,   0.28,   0.04],\n",
       "       [  1.  ,   4.9 ,   3.  , ...,   1.96,   0.28,   0.04],\n",
       "       [  1.  ,   4.7 ,   3.2 , ...,   1.69,   0.26,   0.04],\n",
       "       ..., \n",
       "       [  1.  ,   6.5 ,   3.  , ...,  27.04,  10.4 ,   4.  ],\n",
       "       [  1.  ,   6.2 ,   3.4 , ...,  29.16,  12.42,   5.29],\n",
       "       [  1.  ,   5.9 ,   3.  , ...,  26.01,   9.18,   3.24]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#多项式转换\n",
    "PolynomialFeatures().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 特征选择\n",
    "\n",
    "特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。\n",
    "\n",
    "特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。\n",
    "\n",
    "**根据特征选择的形式又可以将特征选择方法分为3种：**\n",
    "\n",
    "Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "\n",
    "Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。\n",
    "\n",
    "Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。\n",
    "\n",
    "*使用sklearn中的feature_selection库来进行特征选择*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 作业相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个人理解：\n",
    "1. 由于数据没给特征矩阵，所以要先自己根据数据构造特征矩阵\n",
    "\n",
    "### 1.特征构造（参考别人的构造先构造一波）\n",
    "1.1. Count of vowels in word\n",
    "\n",
    "1.2. The vowels in word\n",
    "\n",
    "1.3. The phonemes before each vowel(Assume 4 vowels) \n",
    "\n",
    "1.4. The phonemes after each vowel(Assume 4 vowels) \n",
    "\n",
    "1.5. The type of the word\n",
    "\n",
    "1.6. prefix in word\n",
    "\n",
    "1.7. suffix in word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = helper.read_data('./asset/training_data.txt')\n",
    "\n",
    "#定义元辅音集合\n",
    "vowel = \"AA, AE, AH, AO, AW, AY, EH, ER, EY, IH, IY, OW, OY, UH, UW\".replace(\",\",\"\").split()\n",
    "consonant = \"P, B, CH, D, DH, F, G, HH, JH, K, L, M, N, NG, R, S, SH, T, TH, V, W, Y, Z, ZH\".replace(\",\",\"\").split()\n",
    "\n",
    "#元、辅音合集合\n",
    "vowelAndconsonan = vowel + consonant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA',\n",
       " 'AE',\n",
       " 'AH',\n",
       " 'AO',\n",
       " 'AW',\n",
       " 'AY',\n",
       " 'EH',\n",
       " 'ER',\n",
       " 'EY',\n",
       " 'IH',\n",
       " 'IY',\n",
       " 'OW',\n",
       " 'OY',\n",
       " 'UH',\n",
       " 'UW',\n",
       " 'P',\n",
       " 'B',\n",
       " 'CH',\n",
       " 'D',\n",
       " 'DH',\n",
       " 'F',\n",
       " 'G',\n",
       " 'HH',\n",
       " 'JH',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'NG',\n",
       " 'R',\n",
       " 'S',\n",
       " 'SH',\n",
       " 'T',\n",
       " 'TH',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'ZH']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "vowelAndconsonan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COED</td>\n",
       "      <td>K OW1 EH2 D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PURVIEW</td>\n",
       "      <td>P ER1 V Y UW2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEHIR</td>\n",
       "      <td>HH EH1 HH IH0 R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSCLING</td>\n",
       "      <td>M AH1 S AH0 L IH0 NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NONPOISONOUS</td>\n",
       "      <td>N AA0 N P OY1 Z AH0 N AH0 S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LAVECCHIA</td>\n",
       "      <td>L AA0 V EH1 K IY0 AH0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BUCKLED</td>\n",
       "      <td>B AH1 K AH0 L D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EATEN</td>\n",
       "      <td>IY1 T AH0 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SCIMED</td>\n",
       "      <td>S AY1 M EH2 D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZHAMBU</td>\n",
       "      <td>Z AA0 M B UW1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word                Pronunciation\n",
       "0          COED                  K OW1 EH2 D\n",
       "1       PURVIEW                P ER1 V Y UW2\n",
       "2         HEHIR              HH EH1 HH IH0 R\n",
       "3      MUSCLING         M AH1 S AH0 L IH0 NG\n",
       "4  NONPOISONOUS  N AA0 N P OY1 Z AH0 N AH0 S\n",
       "5     LAVECCHIA        L AA0 V EH1 K IY0 AH0\n",
       "6       BUCKLED              B AH1 K AH0 L D\n",
       "7         EATEN                  IY1 T AH0 N\n",
       "8        SCIMED                S AY1 M EH2 D\n",
       "9        ZHAMBU                Z AA0 M B UW1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./asset/pd_TrainData.txt', sep=':')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获取前缀后缀, 直接用了别人的\n",
    "def s_has_pre(s):\n",
    "    pre = \"an,dis,in,ig,il,im,ir,ne,n,non,neg,un,male,mal,pseudo,mis,de\\\n",
    "    un,anti,ant,contra,contre,contro,counter,ob,oc,of,op,with,by,circum,\\\n",
    "    circu,de,en,ex,ec,es,fore,in,il,im,ir,inter,intel,intro,medi,med,mid,out,\\\n",
    "    over,post,pre,pro,sub,suc,suf,sug,sup,sur,sus,sur,trans,under,up,\\\n",
    "    ante,anti,ex,fore,mid,medi,post,pre,pri,out,over,post,pre,pro,sub,suc,suf,\\\n",
    "    sug,sum,sup,sur,sus,super,sur,trans,under,up,ante,anti,ex,fore,mid,medi,post,\\\n",
    "    pre,pri,pro,re,by,extra,hyper,out,over,sub,suc,sur,super,sur,under,vice,com,\\\n",
    "    cop,con,cor,co,syn,syl,sym,al,over,pan,ex,for,re,se,dia,per,pel,trans，ad,\\\n",
    "    ac,af,ag,an,ap,ar,as,at,ambi,bin,di,twi,tri,thir,deca,deco,dec,deci,hecto,\\\n",
    "    hect,centi,kilo,myria,mega,micro,multi,poly,hemi,demi,semi,pene,arch,auto,bene,\\\n",
    "    eu,male,mal,macro,magni,micro,aud,bio,ge,phon,tele,\\\n",
    "    ac,ad,af,ag,al,an,ap,as,at,an,ab,abs,acer,acid,acri,act,ag,acu,aer,aero,ag,agi,\\\n",
    "    ig,act,agri,agro,alb,albo,ali,allo,alter,alt,am,ami,amor,ambi,ambul,ana,ano,andr,\\\n",
    "    andro,ang,anim,ann,annu,enni,ante,anthrop,anti,ant,anti,antico,apo,ap,aph,aqu,arch,\\\n",
    "    aster,astr,auc,aug,aut,aud,audi,aur,aus,aug,auc,aut,auto,bar,be,belli,bene,bi,bine,\\\n",
    "    bibl,bibli,biblio,bio,bi,brev,cad,cap,cas,ceiv,cept,capt,cid,cip,cad,cas,calor,capit,\\\n",
    "    capt,carn,cat,cata,cath,caus,caut,cause,cuse,cus,ceas,ced,cede,ceed,cess,cent,centr,\\\n",
    "    centri,chrom,chron,cide,cis,cise,circum,cit,civ,clam,claim,clin,clud,clusclaus,co,cog,\\\n",
    "    col,coll,con,com,cor,cogn,gnos,com,con,contr,contra,counter,cord,cor,cardi,corp,cort,\\\n",
    "    cosm,cour,cur,curr,curs,crat,cracy,cre,cresc,cret,crease,crea,cred,cresc,cret,crease,\\\n",
    "    cru,crit,cur,curs,cura,cycl,cyclo,de,dec,deca,dec,dign,dei,div,dem,demo,dent,dont,derm,\\\n",
    "    di,dy,dia,dic,dict,dit,dis,dif,dit,doc,doct,domin,don,dorm,dox,duc,duct,dura,dynam,dys,\\\n",
    "    ec,eco,ecto,en,em,end,epi,equi,erg,ev,et,ex,exter,extra,extro,fa,fess,fac,fact,fec,fect,\\\n",
    "    fic,fas,fea,fall,fals,femto,fer,fic,feign,fain,fit,feat,fid,fid,fide,feder,fig,fila,fili,\\\n",
    "    fin,fix,flex,flect,flict,flu,fluc,fluv,flux,for,fore,forc,fort,form,fract,frag,frai,fuge,\\\n",
    "    fuse,gam,gastr,gastro,gen,gen,geo,germ,gest,giga,gin,gloss,glot,glu,glo,gor,grad,gress\\\n",
    "    ,gree,graph,gram,graf,grat,grav,greg,hale,heal,helio,hema,hemo,her,here,hes,hetero,hex\\\n",
    "    ,ses,sex,homo,hum,human,hydr,hydra,hydro,hyper,hypn,an,ics,ignis,in,im,in,im,il,ir,infra\\\n",
    "    ,inter,intra,intro,ty,jac,ject,join,junct,judice,jug,junct,just,juven,labor,lau,lav,lot\\\n",
    "    ,lut,lect,leg,lig,leg,levi,lex,leag,leg,liber,liver,lide,liter,loc,loco,log,logo,ology\\\n",
    "    ,loqu,locut,luc,lum,lun,lus,lust,lude,macr,macer,magn,main,mal,man,manu,mand,mania,mar\\\n",
    "    ,mari,mer,matri,medi,mega,mem,ment,meso,meta,meter,metr,micro,migra,mill,kilo,milli,min\\\n",
    "    ,mis,mit,miss,mob,mov,mot,mon,mono,mor,mort,morph,multi,nano,nasc,nat,gnant,nai,nat,nasc\\\n",
    "    ,neo,neur,nom,nom,nym,nomen,nomin,non,non,nov,nox,noc,numer,numisma,ob,oc,of,op,oct,oligo\\\n",
    "    ,omni,onym,oper,ortho,over,pac,pair,pare,paleo,pan,para,pat,pass,path,pater,patr,path,pathy\\\n",
    "    ,ped,pod,pedo,pel,puls,pend,pens,pond,per,peri,phage,phan,phas,phen,fan,phant,fant,phe,phil\\\n",
    "    ,phlegma,phobia,phobos,phon,phot,photo,pico,pict,plac,plais,pli,ply,plore,plu,plur,plus,pneuma\\\n",
    "    ,pneumon,pod,poli,poly,pon,pos,pound,pop,port,portion,post,pot,pre,pur,prehendere,prin,prim,\\\n",
    "    prime,pro,proto,psych,punct,pute,quat,quad,quint,penta,quip,quir,quis,quest,quer,re,reg,recti\\\n",
    "    ,retro,ri,ridi,risi,rog,roga,rupt,sacr,sanc,secr,salv,salu,sanct,sat,satis,sci,scio,scientia,\\\n",
    "    scope,scrib,script,se,sect,sec,sed,sess,sid,semi,sen,scen,sent,sens,sept,sequ,secu,sue,serv,\\\n",
    "    sign,signi,simil,simul,sist,sta,stit,soci,sol,solus,solv,solu,solut,somn,soph,spec,spect,spi,\\\n",
    "    spic,sper,sphere,spir,stand,stant,stab,stat,stan,sti,sta,st,stead,strain,strict,string,stige,\\\n",
    "    stru,struct,stroy,stry,sub,suc,suf,sup,sur,sus,sume,sump,super,supra,syn,sym,tact,tang,tag,tig,\\\n",
    "    ting,tain,ten,tent,tin,tect,teg,tele,tem,tempo,ten,tin,tain,tend,tent,tens,tera,term,terr,terra,\\\n",
    "    test,the,theo,therm,thesis,thet,tire,tom,tor,tors,tort,tox,tract,tra,trai,treat,trans,tri,trib,\\\n",
    "    tribute,turbo,typ,ultima,umber,umbraticum,un,uni,vac,vade,vale,vali,valu,veh,vect,ven,vent,ver,\\\n",
    "    veri,verb,verv,vert,vers,vi,vic,vicis,vict,vinc,vid,vis,viv,vita,vivi,voc,voke,vol,volcan,volv\\\n",
    "    ,volt,vol,vor,with,zo\".replace(\" \",\"\").split(\",\")\n",
    "    for i in pre:\n",
    "        if s.startswith(i.upper()):\n",
    "            return 1\n",
    "    return 0\n",
    "def s_has_end(s):\n",
    "    end = \"ee,ese,esque,se,eer,ique,ty,less,ness,ly,ible,able,ion,ic,ical,al,ian,ic,\\\n",
    "    ion,ity,ment,ed,es,er,est,or,ary,ory,ous,cy,ry,ty,al,ure,ute,ble,ar,ly,less,ful,ing,\\\n",
    "    ,inal,tion,sion,osis,oon,sce,\\\n",
    "    que,ette,eer,ee,aire,able,ible,acy,cy,ade,age,al,al,ial,ical,an,ance,ence,ancy,\\\n",
    "    ency,ant,ent,ant,ent,ient,ar,ary,ard,art,ate,ate,ate,ation,cade,drome,ed,ed,en,en,\\\n",
    "    ence,ency,er,ier,er,or,er,or,ery,es,ese,ies,es,ies,ess,est,iest,fold,ful,ful,fy,ia,\\\n",
    "    ian,iatry,ic,ic,ice,ify,ile,ing,ion,ish,ism,ist,ite,ity,ive,ive,ative,itive,ize,less,\\\n",
    "    ly,ment,ness,or,ory,ous,eous,ose,ious,ship,ster,ure,ward,wise,ize,phy,ogy,ity,ion,ic,ical,al\".replace(\" \",\"\").split(\",\")\n",
    "    for i in end:\n",
    "        if s.endswith(i.upper()):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入测试音标获取 目标值，元音数, 音标序列，元音序列, 有无对应前缀， 有无对应后缀\n",
    "\n",
    "def getInfoOfProns(word, prons):\n",
    "    hasPre = s_has_pre(word)\n",
    "    hasEnd = s_has_end(word)\n",
    "    pronsSeq = []\n",
    "    vowelsSeq = []\n",
    "    stressVowelIndex = 0\n",
    "    count = 0\n",
    "    sub_prons = prons.split(' ')\n",
    "    for i in range(len(sub_prons)):\n",
    "        if sub_prons[i][-1].isdigit():\n",
    "            pronsSeq.append(vowel.index(sub_prons[i][0:-1])) #取得元音在元音集合中的序号\n",
    "            vowelsSeq.append(vowelAndconsonan.index(sub_prons[i][0:-1])) #取得元音在元、辅音集合中的序号\n",
    "            count+=1\n",
    "            if sub_prons[i][-1] == '1':\n",
    "                stressVowelIndex = count\n",
    "        else:\n",
    "            vowelsSeq.append(vowel.index(vowelAndconsonan[i])) #取得辅音在元辅、音集合中的序号\n",
    "    return stressVowelIndex, count, pronsSeq, vowelsSeq, hasPre, hasEnd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUSCLING M AH1 S AH0 L IH0 NG\n",
      "1 3 [2, 2, 9] [0, 2, 2, 2, 4, 9, 6] 0 1\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "a1, a2 = training_data[3].split(':')\n",
    "print(a1, a2)\n",
    "b1, b2, b3, b4, b5, b6 = getInfoOfProns(a1, a2)\n",
    "print(b1, b2, b3, b4, b5, b6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetArr = []\n",
    "countArr = []\n",
    "pronsSeqArr = [] \n",
    "vowelsSeqArr = []\n",
    "hasPreArr = []\n",
    "hasEndArr = []\n",
    "\n",
    "for i in range(len(training_data)):\n",
    "    t_word, t_prons = training_data[i].split(':')\n",
    "    t1, t2, t3, t4, t5, t6 = getInfoOfProns(t_word, t_prons)\n",
    "    targetArr.append(t1)\n",
    "    countArr.append(t2)\n",
    "    pronsSeqArr.append(t3) \n",
    "    vowelsSeqArr.append(t4)\n",
    "    hasPreArr.append(t5)\n",
    "    hasEndArr.append(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>pronsSeq</th>\n",
       "      <th>target</th>\n",
       "      <th>vowelsSeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>COED:K OW1 EH2 D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 6]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 11, 6, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PURVIEW:P ER1 V Y UW2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[7, 14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 7, 2, 3, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>HEHIR:HH EH1 HH IH0 R</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 6, 2, 9, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MUSCLING:M AH1 S AH0 L IH0 NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 2, 9]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 2, 2, 2, 4, 9, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NONPOISONOUS:N AA0 N P OY1 Z AH0 N AH0 S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 12, 2, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 2, 3, 12, 5, 2, 7, 2, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                      data  hasEnd  hasPre  \\\n",
       "0      2                          COED:K OW1 EH2 D       1       1   \n",
       "1      2                     PURVIEW:P ER1 V Y UW2       1       1   \n",
       "2      2                     HEHIR:HH EH1 HH IH0 R       1       0   \n",
       "3      3             MUSCLING:M AH1 S AH0 L IH0 NG       1       0   \n",
       "4      4  NONPOISONOUS:N AA0 N P OY1 Z AH0 N AH0 S       1       1   \n",
       "\n",
       "        pronsSeq  target                        vowelsSeq  \n",
       "0        [11, 6]       1                    [0, 11, 6, 3]  \n",
       "1        [7, 14]       1                 [0, 7, 2, 3, 14]  \n",
       "2         [6, 9]       1                  [0, 6, 2, 9, 4]  \n",
       "3      [2, 2, 9]       1            [0, 2, 2, 2, 4, 9, 6]  \n",
       "4  [0, 12, 2, 2]       2  [0, 0, 2, 3, 12, 5, 2, 7, 2, 9]  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'data' : training_data,\n",
    "                   'target' : targetArr,\n",
    "                   'count' : countArr,\n",
    "                   'pronsSeq' : pronsSeqArr,\n",
    "                   'vowelsSeq' : vowelsSeqArr,\n",
    "                   'hasPre' : hasPreArr,\n",
    "                   'hasEnd' : hasEndArr\n",
    "})\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>pronsSeq</th>\n",
       "      <th>vowelsSeq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data  hasEnd  hasPre  pronsSeq  vowelsSeq\n",
       "count target                                            \n",
       "2     1       24435   24435   24435     24435      24435\n",
       "      2        3184    3184    3184      3184       3184\n",
       "3     1        8938    8938    8938      8938       8938\n",
       "      2        6903    6903    6903      6903       6903\n",
       "      3         554     554     554       554        554\n",
       "4     1        1441    1441    1441      1441       1441\n",
       "      2        2135    2135    2135      2135       2135\n",
       "      3        2356    2356    2356      2356       2356\n",
       "      4          54      54      54        54         54"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['count', 'target']).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
