{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献：\n",
    "pickle使用: http://www.cnblogs.com/pzxbc/archive/2012/03/18/2404715.html\n",
    "\n",
    "sklearn: http://www.cnblogs.com/jasonfreak/p/5448462.html\n",
    "\n",
    "\n",
    "数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 特征工程学习用例\n",
    "\n",
    "\n",
    "使用sklearn中的IRIS（鸢尾花）数据集来对特征处理功能进行说明。IRIS数据集由Fisher在1936年整理，包含4个特征（Sepal.Length（花萼长度）、Sepal.Width（花萼宽度）、Petal.Length（花瓣长度）、Petal.Width（花瓣宽度）），特征值都为正浮点数，单位为厘米。目标值为鸢尾花的分类（Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），Iris Virginica（维吉尼亚鸢尾））。导入IRIS数据集的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L0范数是指向量中非0的元素的个数。\n",
    "\n",
    "L1范数是指向量中各个元素绝对值之和\n",
    "\n",
    "L2范数是指向量各元素的平方和然后求平方根"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 预处理学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#标准化，返回值为标准化后的数据\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "StandardScaler().fit_transform(iris.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#区间缩放，返回值为缩放到[0, 1]区间的数据\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MinMaxScaler().fit_transform(iris.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化与归一化的区别\n",
    "\n",
    "　　简单来说，标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，将样本的特征值转换到同一量纲下。归一化是依照特征矩阵的行处理数据，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”。规则为l2的归一化公式如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#归一化，返回值为归一化后的数据\n",
    "from sklearn.preprocessing import Normalizer\n",
    "Normalizer().fit_transform(iris.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#多项式转换\n",
    "PolynomialFeatures().fit_transform(iris.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 特征选择\n",
    "\n",
    "特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。\n",
    "\n",
    "特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。\n",
    "\n",
    "**根据特征选择的形式又可以将特征选择方法分为3种：**\n",
    "\n",
    "Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "\n",
    "Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。\n",
    "\n",
    "Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。\n",
    "\n",
    "*使用sklearn中的feature_selection库来进行特征选择*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 作业相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个人理解：\n",
    "1. 由于数据没给特征矩阵，所以要先自己根据数据构造特征矩阵\n",
    "2. 没有缺失值，维数不大，所以基本不需要降维，规格化也不用，因为特征值都是我们生成的，但预处理需要处理noise之类\n",
    "\n",
    "### 1.特征构造（参考别人的构造先构造一波）\n",
    "1.1. Count of vowels in word\n",
    "\n",
    "1.2. The vowels in word\n",
    "\n",
    "1.3. The phonemes before each vowel \n",
    "\n",
    "1.4. The phonemes after each vowel \n",
    "\n",
    "1.5. prefix in word\n",
    "\n",
    "1.6. suffix in word（验证无用，方差为0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = helper.read_data('./asset/training_data.txt')\n",
    "testing_data = helper.read_data('./asset/tiny_test.txt')\n",
    "\n",
    "#定义元辅音集合\n",
    "vowel = \"AA, AE, AH, AO, AW, AY, EH, ER, EY, IH, IY, OW, OY, UH, UW\".replace(\",\",\"\").split()\n",
    "consonant = \"P, B, CH, D, DH, F, G, HH, JH, K, L, M, N, NG, R, S, SH, T, TH, V, W, Y, Z, ZH\".replace(\",\",\"\").split()\n",
    "\n",
    "#元、辅音合集合\n",
    "vowelAndconsonan = vowel + consonant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATA:D EY T AH', 'MINING:M AY N IH NG', 'MACHINE:M AH SH IY N', 'LEARNING:L ER N IH NG']\n"
     ]
    }
   ],
   "source": [
    "print(testing_data) #test data太少，直接用train中的50000个进行交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COED</td>\n",
       "      <td>K OW1 EH2 D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PURVIEW</td>\n",
       "      <td>P ER1 V Y UW2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEHIR</td>\n",
       "      <td>HH EH1 HH IH0 R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSCLING</td>\n",
       "      <td>M AH1 S AH0 L IH0 NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NONPOISONOUS</td>\n",
       "      <td>N AA0 N P OY1 Z AH0 N AH0 S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word                Pronunciation\n",
       "0          COED                  K OW1 EH2 D\n",
       "1       PURVIEW                P ER1 V Y UW2\n",
       "2         HEHIR              HH EH1 HH IH0 R\n",
       "3      MUSCLING         M AH1 S AH0 L IH0 NG\n",
       "4  NONPOISONOUS  N AA0 N P OY1 Z AH0 N AH0 S"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从读入的data里面构建dataframe\n",
    "labels = ['Word', 'Pronunciation']\n",
    "df_train = pd.DataFrame.from_records([(x.split(':')[0], x.split(':')[1]) for x in training_data], columns=labels)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获取前缀后缀, 直接用了别人的\n",
    "def s_has_pre(s):\n",
    "    pre = \"an,dis,in,ig,il,im,ir,ne,n,non,neg,un,male,mal,pseudo,mis,de\\\n",
    "    un,anti,ant,contra,contre,contro,counter,ob,oc,of,op,with,by,circum,\\\n",
    "    circu,de,en,ex,ec,es,fore,in,il,im,ir,inter,intel,intro,medi,med,mid,out,\\\n",
    "    over,post,pre,pro,sub,suc,suf,sug,sup,sur,sus,sur,trans,under,up,\\\n",
    "    ante,anti,ex,fore,mid,medi,post,pre,pri,out,over,post,pre,pro,sub,suc,suf,\\\n",
    "    sug,sum,sup,sur,sus,super,sur,trans,under,up,ante,anti,ex,fore,mid,medi,post,\\\n",
    "    pre,pri,pro,re,by,extra,hyper,out,over,sub,suc,sur,super,sur,under,vice,com,\\\n",
    "    cop,con,cor,co,syn,syl,sym,al,over,pan,ex,for,re,se,dia,per,pel,trans，ad,\\\n",
    "    ac,af,ag,an,ap,ar,as,at,ambi,bin,di,twi,tri,thir,deca,deco,dec,deci,hecto,\\\n",
    "    hect,centi,kilo,myria,mega,micro,multi,poly,hemi,demi,semi,pene,arch,auto,bene,\\\n",
    "    eu,male,mal,macro,magni,micro,aud,bio,ge,phon,tele,\\\n",
    "    ac,ad,af,ag,al,an,ap,as,at,an,ab,abs,acer,acid,acri,act,ag,acu,aer,aero,ag,agi,\\\n",
    "    ig,act,agri,agro,alb,albo,ali,allo,alter,alt,am,ami,amor,ambi,ambul,ana,ano,andr,\\\n",
    "    andro,ang,anim,ann,annu,enni,ante,anthrop,anti,ant,anti,antico,apo,ap,aph,aqu,arch,\\\n",
    "    aster,astr,auc,aug,aut,aud,audi,aur,aus,aug,auc,aut,auto,bar,be,belli,bene,bi,bine,\\\n",
    "    bibl,bibli,biblio,bio,bi,brev,cad,cap,cas,ceiv,cept,capt,cid,cip,cad,cas,calor,capit,\\\n",
    "    capt,carn,cat,cata,cath,caus,caut,cause,cuse,cus,ceas,ced,cede,ceed,cess,cent,centr,\\\n",
    "    centri,chrom,chron,cide,cis,cise,circum,cit,civ,clam,claim,clin,clud,clusclaus,co,cog,\\\n",
    "    col,coll,con,com,cor,cogn,gnos,com,con,contr,contra,counter,cord,cor,cardi,corp,cort,\\\n",
    "    cosm,cour,cur,curr,curs,crat,cracy,cre,cresc,cret,crease,crea,cred,cresc,cret,crease,\\\n",
    "    cru,crit,cur,curs,cura,cycl,cyclo,de,dec,deca,dec,dign,dei,div,dem,demo,dent,dont,derm,\\\n",
    "    di,dy,dia,dic,dict,dit,dis,dif,dit,doc,doct,domin,don,dorm,dox,duc,duct,dura,dynam,dys,\\\n",
    "    ec,eco,ecto,en,em,end,epi,equi,erg,ev,et,ex,exter,extra,extro,fa,fess,fac,fact,fec,fect,\\\n",
    "    fic,fas,fea,fall,fals,femto,fer,fic,feign,fain,fit,feat,fid,fid,fide,feder,fig,fila,fili,\\\n",
    "    fin,fix,flex,flect,flict,flu,fluc,fluv,flux,for,fore,forc,fort,form,fract,frag,frai,fuge,\\\n",
    "    fuse,gam,gastr,gastro,gen,gen,geo,germ,gest,giga,gin,gloss,glot,glu,glo,gor,grad,gress\\\n",
    "    ,gree,graph,gram,graf,grat,grav,greg,hale,heal,helio,hema,hemo,her,here,hes,hetero,hex\\\n",
    "    ,ses,sex,homo,hum,human,hydr,hydra,hydro,hyper,hypn,an,ics,ignis,in,im,in,im,il,ir,infra\\\n",
    "    ,inter,intra,intro,ty,jac,ject,join,junct,judice,jug,junct,just,juven,labor,lau,lav,lot\\\n",
    "    ,lut,lect,leg,lig,leg,levi,lex,leag,leg,liber,liver,lide,liter,loc,loco,log,logo,ology\\\n",
    "    ,loqu,locut,luc,lum,lun,lus,lust,lude,macr,macer,magn,main,mal,man,manu,mand,mania,mar\\\n",
    "    ,mari,mer,matri,medi,mega,mem,ment,meso,meta,meter,metr,micro,migra,mill,kilo,milli,min\\\n",
    "    ,mis,mit,miss,mob,mov,mot,mon,mono,mor,mort,morph,multi,nano,nasc,nat,gnant,nai,nat,nasc\\\n",
    "    ,neo,neur,nom,nom,nym,nomen,nomin,non,non,nov,nox,noc,numer,numisma,ob,oc,of,op,oct,oligo\\\n",
    "    ,omni,onym,oper,ortho,over,pac,pair,pare,paleo,pan,para,pat,pass,path,pater,patr,path,pathy\\\n",
    "    ,ped,pod,pedo,pel,puls,pend,pens,pond,per,peri,phage,phan,phas,phen,fan,phant,fant,phe,phil\\\n",
    "    ,phlegma,phobia,phobos,phon,phot,photo,pico,pict,plac,plais,pli,ply,plore,plu,plur,plus,pneuma\\\n",
    "    ,pneumon,pod,poli,poly,pon,pos,pound,pop,port,portion,post,pot,pre,pur,prehendere,prin,prim,\\\n",
    "    prime,pro,proto,psych,punct,pute,quat,quad,quint,penta,quip,quir,quis,quest,quer,re,reg,recti\\\n",
    "    ,retro,ri,ridi,risi,rog,roga,rupt,sacr,sanc,secr,salv,salu,sanct,sat,satis,sci,scio,scientia,\\\n",
    "    scope,scrib,script,se,sect,sec,sed,sess,sid,semi,sen,scen,sent,sens,sept,sequ,secu,sue,serv,\\\n",
    "    sign,signi,simil,simul,sist,sta,stit,soci,sol,solus,solv,solu,solut,somn,soph,spec,spect,spi,\\\n",
    "    spic,sper,sphere,spir,stand,stant,stab,stat,stan,sti,sta,st,stead,strain,strict,string,stige,\\\n",
    "    stru,struct,stroy,stry,sub,suc,suf,sup,sur,sus,sume,sump,super,supra,syn,sym,tact,tang,tag,tig,\\\n",
    "    ting,tain,ten,tent,tin,tect,teg,tele,tem,tempo,ten,tin,tain,tend,tent,tens,tera,term,terr,terra,\\\n",
    "    test,the,theo,therm,thesis,thet,tire,tom,tor,tors,tort,tox,tract,tra,trai,treat,trans,tri,trib,\\\n",
    "    tribute,turbo,typ,ultima,umber,umbraticum,un,uni,vac,vade,vale,vali,valu,veh,vect,ven,vent,ver,\\\n",
    "    veri,verb,verv,vert,vers,vi,vic,vicis,vict,vinc,vid,vis,viv,vita,vivi,voc,voke,vol,volcan,volv\\\n",
    "    ,volt,vol,vor,with,zo\".replace(\" \",\"\").split(\",\")\n",
    "    for i in pre:\n",
    "        if s.startswith(i.upper()):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# 验证无用\n",
    "def s_has_end(s):\n",
    "    end = \"ee,ese,esque,se,eer,ique,ty,less,ness,ly,ible,able,ion,ic,ical,al,ian,ic,\\\n",
    "    ion,ity,ment,ed,es,er,est,or,ary,ory,ous,cy,ry,ty,al,ure,ute,ble,ar,ly,less,ful,ing,\\\n",
    "    ,inal,tion,sion,osis,oon,sce,\\\n",
    "    que,ette,eer,ee,aire,able,ible,acy,cy,ade,age,al,al,ial,ical,an,ance,ence,ancy,\\\n",
    "    ency,ant,ent,ant,ent,ient,ar,ary,ard,art,ate,ate,ate,ation,cade,drome,ed,ed,en,en,\\\n",
    "    ence,ency,er,ier,er,or,er,or,ery,es,ese,ies,es,ies,ess,est,iest,fold,ful,ful,fy,ia,\\\n",
    "    ian,iatry,ic,ic,ice,ify,ile,ing,ion,ish,ism,ist,ite,ity,ive,ive,ative,itive,ize,less,\\\n",
    "    ly,ment,ness,or,ory,ous,eous,ose,ious,ship,ster,ure,ward,wise,ize,phy,ogy,ity,ion,ic,ical,al\".replace(\" \",\"\").split(\",\")\n",
    "    for i in end:\n",
    "        if s.endswith(i.upper()):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入训练单词和音标获取：目标值，元音数, 音标序列，元音序列, 有无对应前缀，有无对应后缀\n",
    "def getInfoOfPronsFromTrain(word, prons):\n",
    "    hasPre = s_has_pre(word)\n",
    "    hasEnd = s_has_end(word)\n",
    "    pronsSeq = []\n",
    "    vowelsSeq = []\n",
    "    stressVowelIndex = 0\n",
    "    count = 0\n",
    "    sub_prons = prons.split(' ')\n",
    "    for i in range(len(sub_prons)):\n",
    "        if sub_prons[i][-1].isdigit():\n",
    "            vowelsSeq.append(vowel.index(sub_prons[i][0:-1])) #取得元音在元音集合中的序号\n",
    "            pronsSeq.append(vowelAndconsonan.index(sub_prons[i][0:-1])) #取得元音在元、辅音集合中的序号\n",
    "            count+=1\n",
    "            if sub_prons[i][-1] == '1':\n",
    "                stressVowelIndex = count\n",
    "        else:\n",
    "            pronsSeq.append(vowelAndconsonan.index(sub_prons[i])) #取得辅音在元辅、音集合中的序号\n",
    "    return stressVowelIndex, count, pronsSeq, vowelsSeq, hasPre, hasEnd\n",
    "\n",
    "#输入测试单词和目标获取：元音数, 音标序列，元音序列, 有无对应前缀，有无对应后缀\n",
    "def getInfoOfPronsFromTest(word, prons):\n",
    "    hasPre = s_has_pre(word)\n",
    "    hasEnd = s_has_end(word)\n",
    "    pronsSeq = []\n",
    "    vowelsSeq = []\n",
    "    count = 0\n",
    "    sub_prons = prons.split(' ')\n",
    "    for i in range(len(sub_prons)):\n",
    "        if sub_prons[i] in vowel:\n",
    "            vowelsSeq.append(vowel.index(sub_prons[i])) #取得元音在元音集合中的序号\n",
    "            count+=1\n",
    "        pronsSeq.append(vowelAndconsonan.index(sub_prons[i])) #取得辅音在元辅、音集合中的序号\n",
    "    return count, pronsSeq, vowelsSeq, hasPre, hasEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUSCLING M AH1 S AH0 L IH0 NG\n",
      "1 3 [26, 2, 30, 2, 25, 9, 28] [2, 2, 9] 0 1\n",
      "LEARNING L ER N IH NG\n",
      "2 [25, 7, 27, 9, 28] [7, 9] 0 1\n"
     ]
    }
   ],
   "source": [
    "## function test\n",
    "a1, a2 = training_data[3].split(':')\n",
    "print(a1, a2)\n",
    "b1, b2, b3, b4, b5, b6 = getInfoOfPronsFromTrain(a1, a2)\n",
    "print(b1, b2, b3, b4, b5, b6)\n",
    "\n",
    "a1, a2 = testing_data[3].split(':')\n",
    "print(a1, a2)\n",
    "b1, b2, b3, b4, b5= getInfoOfPronsFromTest(a1, a2)\n",
    "print(b1, b2, b3, b4, b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetArr = []\n",
    "countArr = []\n",
    "pronsSeqArr = [] \n",
    "vowelsSeqArr = []\n",
    "hasPreArr = []\n",
    "hasEndArr = []\n",
    "\n",
    "for i in range(len(training_data)):\n",
    "    t_word, t_prons = training_data[i].split(':')\n",
    "    t1, t2, t3, t4, t5, t6 = getInfoOfPronsFromTrain(t_word, t_prons)\n",
    "    targetArr.append(t1)\n",
    "    countArr.append(t2)\n",
    "    pronsSeqArr.append(t3) \n",
    "    vowelsSeqArr.append(t4)\n",
    "    hasPreArr.append(t5)\n",
    "    hasEndArr.append(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = 999\n",
    "for i in range (len(testing_data)):\n",
    "    t_word, t_prons = testing_data[i].split(':')\n",
    "    a = getInfoOfPronsFromTest(t_word, t_prons)\n",
    "    if a[0] < mm:\n",
    "        mm = a[0]\n",
    "\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>pronsSeq</th>\n",
       "      <th>target</th>\n",
       "      <th>vowelsSeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>COED:K OW1 EH2 D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[24, 11, 6, 18]</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PURVIEW:P ER1 V Y UW2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 7, 34, 36, 14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>HEHIR:HH EH1 HH IH0 R</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[22, 6, 22, 9, 29]</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MUSCLING:M AH1 S AH0 L IH0 NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[26, 2, 30, 2, 25, 9, 28]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2, 2, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NONPOISONOUS:N AA0 N P OY1 Z AH0 N AH0 S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[27, 0, 27, 15, 12, 37, 2, 27, 2, 30]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 12, 2, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                      data  hasEnd  hasPre  \\\n",
       "0      2                          COED:K OW1 EH2 D       1       1   \n",
       "1      2                     PURVIEW:P ER1 V Y UW2       1       1   \n",
       "2      2                     HEHIR:HH EH1 HH IH0 R       1       0   \n",
       "3      3             MUSCLING:M AH1 S AH0 L IH0 NG       1       0   \n",
       "4      4  NONPOISONOUS:N AA0 N P OY1 Z AH0 N AH0 S       1       1   \n",
       "\n",
       "                                pronsSeq  target      vowelsSeq  \n",
       "0                        [24, 11, 6, 18]       1        [11, 6]  \n",
       "1                    [15, 7, 34, 36, 14]       1        [7, 14]  \n",
       "2                     [22, 6, 22, 9, 29]       1         [6, 9]  \n",
       "3              [26, 2, 30, 2, 25, 9, 28]       1      [2, 2, 9]  \n",
       "4  [27, 0, 27, 15, 12, 37, 2, 27, 2, 30]       2  [0, 12, 2, 2]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'data' : training_data,\n",
    "                   'target' : targetArr,\n",
    "                   'count' : countArr,\n",
    "                   'pronsSeq' : pronsSeqArr,\n",
    "                   'vowelsSeq' : vowelsSeqArr,\n",
    "                   'hasPre' : hasPreArr,\n",
    "                   'hasEnd' : hasEndArr\n",
    "})\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.567340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443140</td>\n",
       "      <td>1.364080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.696358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>0.595326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count   hasEnd        hasPre        target\n",
       "count  50000.000000  50000.0  50000.000000  50000.000000\n",
       "mean       2.567340      1.0      0.443140      1.364080\n",
       "std        0.696358      0.0      0.496761      0.595326\n",
       "min        2.000000      1.0      0.000000      1.000000\n",
       "25%        2.000000      1.0      0.000000      1.000000\n",
       "50%        2.000000      1.0      0.000000      1.000000\n",
       "75%        3.000000      1.0      1.000000      2.000000\n",
       "max        4.000000      1.0      1.000000      4.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length in pronsSeq 14\n",
      "max length in vowelsSeq 4\n"
     ]
    }
   ],
   "source": [
    "#看看最长的音标数\n",
    "print('max length in pronsSeq', max([len(x) for x in pronsSeqArr]))\n",
    "\n",
    "##看看最长的元音数\n",
    "print('max length in vowelsSeq',  max([len(x) for x in vowelsSeqArr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 研究发现hasEnd的方差为0，舍去,  同时发现元音长度是一个很好的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>pronsSeq</th>\n",
       "      <th>vowelsSeq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "      <td>24435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "      <td>3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "      <td>8938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "      <td>6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "      <td>2135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "      <td>2356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data  hasEnd  hasPre  pronsSeq  vowelsSeq\n",
       "count target                                            \n",
       "2     1       24435   24435   24435     24435      24435\n",
       "      2        3184    3184    3184      3184       3184\n",
       "3     1        8938    8938    8938      8938       8938\n",
       "      2        6903    6903    6903      6903       6903\n",
       "      3         554     554     554       554        554\n",
       "4     1        1441    1441    1441      1441       1441\n",
       "      2        2135    2135    2135      2135       2135\n",
       "      3        2356    2356    2356      2356       2356\n",
       "      4          54      54      54        54         54"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['count', 'target']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵0\n",
    "labels_0 = []\n",
    "for i in range(len(training_data)):\n",
    "    labels_0.append([countArr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵1\n",
    "labels_1 = []\n",
    "for i in range(len(training_data)):\n",
    "    labels_1.append([countArr[i], hasPreArr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pronsSeqArr2 = []\n",
    "\n",
    "for temp in pronsSeqArr:\n",
    "    k = 14 - len(temp)\n",
    "    temp += [-1] * k\n",
    "    pronsSeqArr2.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵2\n",
    "labels_2 = []\n",
    "for i in range(len(training_data)):\n",
    "    tempList = [countArr[i], hasPreArr[i]]\n",
    "    tempList += pronsSeqArr2[i];\n",
    "    labels_2.append(tempList)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵3\n",
    "vowelsSeqArr2 = []\n",
    "\n",
    "for temp in vowelsSeqArr:\n",
    "    k = 4 - len(temp)\n",
    "    temp += [-1] * k\n",
    "    vowelsSeqArr2.append(temp)   \n",
    "\n",
    "labels_3 = []\n",
    "for i in range(len(training_data)):\n",
    "    tempList = [countArr[i], hasPreArr[i]]\n",
    "    tempList += vowelsSeqArr2[i];\n",
    "    labels_3.append(tempList) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.567340</td>\n",
       "      <td>0.443140</td>\n",
       "      <td>21.395060</td>\n",
       "      <td>11.627360</td>\n",
       "      <td>21.423140</td>\n",
       "      <td>16.163420</td>\n",
       "      <td>15.755360</td>\n",
       "      <td>12.524680</td>\n",
       "      <td>8.02876</td>\n",
       "      <td>4.453420</td>\n",
       "      <td>1.917060</td>\n",
       "      <td>0.315360</td>\n",
       "      <td>-0.508540</td>\n",
       "      <td>-0.863460</td>\n",
       "      <td>-0.968880</td>\n",
       "      <td>-0.994560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.696358</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>8.999909</td>\n",
       "      <td>10.646194</td>\n",
       "      <td>9.794818</td>\n",
       "      <td>11.248399</td>\n",
       "      <td>12.097586</td>\n",
       "      <td>13.142204</td>\n",
       "      <td>12.68147</td>\n",
       "      <td>10.901336</td>\n",
       "      <td>8.531851</td>\n",
       "      <td>6.009199</td>\n",
       "      <td>3.771807</td>\n",
       "      <td>2.037268</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.432266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       2.567340      0.443140     21.395060     11.627360     21.423140   \n",
       "std        0.696358      0.496761      8.999909     10.646194      9.794818   \n",
       "min        2.000000      0.000000      0.000000      0.000000     -1.000000   \n",
       "25%        2.000000      0.000000     16.000000      2.000000     15.000000   \n",
       "50%        2.000000      0.000000     24.000000      9.000000     25.000000   \n",
       "75%        3.000000      1.000000     29.000000     23.000000     29.000000   \n",
       "max        4.000000      1.000000     38.000000     38.000000     38.000000   \n",
       "\n",
       "                 5             6             7            8             9   \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.00000  50000.000000   \n",
       "mean      16.163420     15.755360     12.524680      8.02876      4.453420   \n",
       "std       11.248399     12.097586     13.142204     12.68147     10.901336   \n",
       "min       -1.000000     -1.000000     -1.000000     -1.00000     -1.000000   \n",
       "25%        7.000000      3.000000     -1.000000     -1.00000     -1.000000   \n",
       "50%       15.000000     15.000000      9.000000     -1.00000     -1.000000   \n",
       "75%       27.000000     27.000000     27.000000     18.00000      2.000000   \n",
       "max       38.000000     38.000000     38.000000     38.00000     38.000000   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       1.917060      0.315360     -0.508540     -0.863460     -0.968880   \n",
       "std        8.531851      6.009199      3.771807      2.037268      0.999346   \n",
       "min       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "25%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "75%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "max       38.000000     37.000000     37.000000     37.000000     37.000000   \n",
       "\n",
       "                 15  \n",
       "count  50000.000000  \n",
       "mean      -0.994560  \n",
       "std        0.432266  \n",
       "min       -1.000000  \n",
       "25%       -1.000000  \n",
       "50%       -1.000000  \n",
       "75%       -1.000000  \n",
       "max       37.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_labels_2 =  pd.DataFrame(labels_2)\n",
    "df_labels_2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(labels_3, targetArr, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30794478,  0.04651302,  0.17737902,  0.27921066,  0.15145235,\n",
       "        0.03750016])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#使用信息熵作为划分标准，对决策树进行训练\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#系数反映每个特征的影响力。越大表示该特征在分类中起到的作用越大\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其实可以看到最后一个影响力为0，可以直接去掉， 其实后4个影响力都极低，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 3]\n",
      "f1 for train =  0.908675\n",
      "f1 for test =  0.8758\n"
     ]
    }
   ],
   "source": [
    "answer = clf.predict(x_train)\n",
    "answer2 = clf.predict(x_test)\n",
    "print(answer)\n",
    "# print(np.mean( answer == y_train))\n",
    "print('f1 for train = ' , f1_score(y_train, answer, average='micro'))\n",
    "print('f1 for test = ' , f1_score(y_test, answer2, average='micro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 for train =  0.705885714286\n",
      "f1 for test =  0.7076\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf_bayes = linear_model.BayesianRidge()\n",
    "clf_bayes.fit(x_train, y_train)\n",
    "answer = clf_bayes.predict(x_train).round() #取整\n",
    "answer2 = clf_bayes.predict(x_test).round()\n",
    "print('f1 for train = ' , f1_score(y_train, answer, average='micro'))\n",
    "print('f1 for test = ' , f1_score(y_test, answer2, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
