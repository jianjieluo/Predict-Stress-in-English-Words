{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献：\n",
    "pickle使用: http://www.cnblogs.com/pzxbc/archive/2012/03/18/2404715.html\n",
    "\n",
    "sklearn: http://www.cnblogs.com/jasonfreak/p/5448462.html\n",
    "\n",
    "sklearn官方文档：http://sklearn.lzjqsdd.com/modules/decomposition.html#decompositions\n",
    "\n",
    "**数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 作业相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个人理解：\n",
    "1. 由于数据没给特征矩阵，所以要先自己根据数据构造特征矩阵\n",
    "2. 没有缺失值，维数不大，所以基本不需要降维，规格化也不用，因为特征值都是我们生成的，但预处理需要处理noise之类\n",
    "3. 关键还是特征要选得好\n",
    "\n",
    "### 1.测试过的特征\n",
    "\n",
    "1. 元音个数 *\n",
    "2. 前缀 *\n",
    "3. 后缀\n",
    "4. 音标个数\n",
    "5. 单词长度\n",
    "6. 元音序列 *\n",
    "7. 音标序列\n",
    "\n",
    "*加星号的效果比较好*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "testing_data = helper.read_data('../asset/tiny_test.txt')\n",
    "\n",
    "#定义元辅音集合\n",
    "vowel = \"AA, AE, AH, AO, AW, AY, EH, ER, EY, IH, IY, OW, OY, UH, UW\".replace(\",\",\"\").split()\n",
    "consonant = \"P, B, CH, D, DH, F, G, HH, JH, K, L, M, N, NG, R, S, SH, T, TH, V, W, Y, Z, ZH\".replace(\",\",\"\").split()\n",
    "\n",
    "#元、辅音合集合\n",
    "vowelAndconsonan = vowel + consonant;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#这里是pd试验田\n",
    "# df_train = pd.read_csv('../asset/pd_TrainData.txt', sep=':')\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获取前缀后缀, 直接用了别人的\n",
    "def s_has_pre(s):\n",
    "    pre = \"an,dis,in,ig,il,im,ir,ne,n,non,neg,un,male,mal,pseudo,mis,de\\\n",
    "    un,anti,ant,contra,contre,contro,counter,ob,oc,of,op,with,by,circum,\\\n",
    "    circu,de,en,ex,ec,es,fore,in,il,im,ir,inter,intel,intro,medi,med,mid,out,\\\n",
    "    over,post,pre,pro,sub,suc,suf,sug,sup,sur,sus,sur,trans,under,up,\\\n",
    "    ante,anti,ex,fore,mid,medi,post,pre,pri,out,over,post,pre,pro,sub,suc,suf,\\\n",
    "    sug,sum,sup,sur,sus,super,sur,trans,under,up,ante,anti,ex,fore,mid,medi,post,\\\n",
    "    pre,pri,pro,re,by,extra,hyper,out,over,sub,suc,sur,super,sur,under,vice,com,\\\n",
    "    cop,con,cor,co,syn,syl,sym,al,over,pan,ex,for,re,se,dia,per,pel,trans，ad,\\\n",
    "    ac,af,ag,an,ap,ar,as,at,ambi,bin,di,twi,tri,thir,deca,deco,dec,deci,hecto,\\\n",
    "    hect,centi,kilo,myria,mega,micro,multi,poly,hemi,demi,semi,pene,arch,auto,bene,\\\n",
    "    eu,male,mal,macro,magni,micro,aud,bio,ge,phon,tele,\\\n",
    "    ac,ad,af,ag,al,an,ap,as,at,an,ab,abs,acer,acid,acri,act,ag,acu,aer,aero,ag,agi,\\\n",
    "    ig,act,agri,agro,alb,albo,ali,allo,alter,alt,am,ami,amor,ambi,ambul,ana,ano,andr,\\\n",
    "    andro,ang,anim,ann,annu,enni,ante,anthrop,anti,ant,anti,antico,apo,ap,aph,aqu,arch,\\\n",
    "    aster,astr,auc,aug,aut,aud,audi,aur,aus,aug,auc,aut,auto,bar,be,belli,bene,bi,bine,\\\n",
    "    bibl,bibli,biblio,bio,bi,brev,cad,cap,cas,ceiv,cept,capt,cid,cip,cad,cas,calor,capit,\\\n",
    "    capt,carn,cat,cata,cath,caus,caut,cause,cuse,cus,ceas,ced,cede,ceed,cess,cent,centr,\\\n",
    "    centri,chrom,chron,cide,cis,cise,circum,cit,civ,clam,claim,clin,clud,clusclaus,co,cog,\\\n",
    "    col,coll,con,com,cor,cogn,gnos,com,con,contr,contra,counter,cord,cor,cardi,corp,cort,\\\n",
    "    cosm,cour,cur,curr,curs,crat,cracy,cre,cresc,cret,crease,crea,cred,cresc,cret,crease,\\\n",
    "    cru,crit,cur,curs,cura,cycl,cyclo,de,dec,deca,dec,dign,dei,div,dem,demo,dent,dont,derm,\\\n",
    "    di,dy,dia,dic,dict,dit,dis,dif,dit,doc,doct,domin,don,dorm,dox,duc,duct,dura,dynam,dys,\\\n",
    "    ec,eco,ecto,en,em,end,epi,equi,erg,ev,et,ex,exter,extra,extro,fa,fess,fac,fact,fec,fect,\\\n",
    "    fic,fas,fea,fall,fals,femto,fer,fic,feign,fain,fit,feat,fid,fid,fide,feder,fig,fila,fili,\\\n",
    "    fin,fix,flex,flect,flict,flu,fluc,fluv,flux,for,fore,forc,fort,form,fract,frag,frai,fuge,\\\n",
    "    fuse,gam,gastr,gastro,gen,gen,geo,germ,gest,giga,gin,gloss,glot,glu,glo,gor,grad,gress\\\n",
    "    ,gree,graph,gram,graf,grat,grav,greg,hale,heal,helio,hema,hemo,her,here,hes,hetero,hex\\\n",
    "    ,ses,sex,homo,hum,human,hydr,hydra,hydro,hyper,hypn,an,ics,ignis,in,im,in,im,il,ir,infra\\\n",
    "    ,inter,intra,intro,ty,jac,ject,join,junct,judice,jug,junct,just,juven,labor,lau,lav,lot\\\n",
    "    ,lut,lect,leg,lig,leg,levi,lex,leag,leg,liber,liver,lide,liter,loc,loco,log,logo,ology\\\n",
    "    ,loqu,locut,luc,lum,lun,lus,lust,lude,macr,macer,magn,main,mal,man,manu,mand,mania,mar\\\n",
    "    ,mari,mer,matri,medi,mega,mem,ment,meso,meta,meter,metr,micro,migra,mill,kilo,milli,min\\\n",
    "    ,mis,mit,miss,mob,mov,mot,mon,mono,mor,mort,morph,multi,nano,nasc,nat,gnant,nai,nat,nasc\\\n",
    "    ,neo,neur,nom,nom,nym,nomen,nomin,non,non,nov,nox,noc,numer,numisma,ob,oc,of,op,oct,oligo\\\n",
    "    ,omni,onym,oper,ortho,over,pac,pair,pare,paleo,pan,para,pat,pass,path,pater,patr,path,pathy\\\n",
    "    ,ped,pod,pedo,pel,puls,pend,pens,pond,per,peri,phage,phan,phas,phen,fan,phant,fant,phe,phil\\\n",
    "    ,phlegma,phobia,phobos,phon,phot,photo,pico,pict,plac,plais,pli,ply,plore,plu,plur,plus,pneuma\\\n",
    "    ,pneumon,pod,poli,poly,pon,pos,pound,pop,port,portion,post,pot,pre,pur,prehendere,prin,prim,\\\n",
    "    prime,pro,proto,psych,punct,pute,quat,quad,quint,penta,quip,quir,quis,quest,quer,re,reg,recti\\\n",
    "    ,retro,ri,ridi,risi,rog,roga,rupt,sacr,sanc,secr,salv,salu,sanct,sat,satis,sci,scio,scientia,\\\n",
    "    scope,scrib,script,se,sect,sec,sed,sess,sid,semi,sen,scen,sent,sens,sept,sequ,secu,sue,serv,\\\n",
    "    sign,signi,simil,simul,sist,sta,stit,soci,sol,solus,solv,solu,solut,somn,soph,spec,spect,spi,\\\n",
    "    spic,sper,sphere,spir,stand,stant,stab,stat,stan,sti,sta,st,stead,strain,strict,string,stige,\\\n",
    "    stru,struct,stroy,stry,sub,suc,suf,sup,sur,sus,sume,sump,super,supra,syn,sym,tact,tang,tag,tig,\\\n",
    "    ting,tain,ten,tent,tin,tect,teg,tele,tem,tempo,ten,tin,tain,tend,tent,tens,tera,term,terr,terra,\\\n",
    "    test,the,theo,therm,thesis,thet,tire,tom,tor,tors,tort,tox,tract,tra,trai,treat,trans,tri,trib,\\\n",
    "    tribute,turbo,typ,ultima,umber,umbraticum,un,uni,vac,vade,vale,vali,valu,veh,vect,ven,vent,ver,\\\n",
    "    veri,verb,verv,vert,vers,vi,vic,vicis,vict,vinc,vid,vis,viv,vita,vivi,voc,voke,vol,volcan,volv\\\n",
    "    ,volt,vol,vor,with,zo\".replace(\" \",\"\").split(\",\")\n",
    "    for i in pre:\n",
    "        if s.startswith(i.upper()):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# 验证无用\n",
    "def s_has_end(s):\n",
    "    end = \"ee,ese,esque,se,eer,ique,ty,less,ness,ly,ible,able,ion,ic,ical,al,ian,ic,\\\n",
    "    ion,ity,ment,ed,es,er,est,or,ary,ory,ous,cy,ry,ty,al,ure,ute,ble,ar,ly,less,ful,ing,\\\n",
    "    ,inal,tion,sion,osis,oon,sce,\\\n",
    "    que,ette,eer,ee,aire,able,ible,acy,cy,ade,age,al,al,ial,ical,an,ance,ence,ancy,\\\n",
    "    ency,ant,ent,ant,ent,ient,ar,ary,ard,art,ate,ate,ate,ation,cade,drome,ed,ed,en,en,\\\n",
    "    ence,ency,er,ier,er,or,er,or,ery,es,ese,ies,es,ies,ess,est,iest,fold,ful,ful,fy,ia,\\\n",
    "    ian,iatry,ic,ic,ice,ify,ile,ing,ion,ish,ism,ist,ite,ity,ive,ive,ative,itive,ize,less,\\\n",
    "    ly,ment,ness,or,ory,ous,eous,ose,ious,ship,ster,ure,ward,wise,ize,phy,ogy,ity,ion,ic,ical,al\".replace(\" \",\"\").split(\",\")\n",
    "    for i in end:\n",
    "        if s.endswith(i.upper()):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下是特征提取的两个函数，因为train数据和test数据是不一样的，train数据有数字，所以给了两个特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入训练单词和音标获取：目标值，单词长度，元音数, 音标序列，元音序列, 有无对应前缀，有无对应后缀\n",
    "def getInfoOfPronsFromTrain(word, prons):\n",
    "    wordLen = len(word)\n",
    "    hasPre = s_has_pre(word)\n",
    "    hasEnd = s_has_end(word)\n",
    "    pronsSeq = []\n",
    "    vowelsSeq = []\n",
    "    stressVowelIndex = 0\n",
    "    count = 0\n",
    "    sub_prons = prons.split(' ')\n",
    "    for i in range(len(sub_prons)):\n",
    "        if sub_prons[i][-1].isdigit():\n",
    "            vowelsSeq.append(vowel.index(sub_prons[i][0:-1])) #取得元音在元音集合中的序号\n",
    "            pronsSeq.append(vowelAndconsonan.index(sub_prons[i][0:-1])) #取得元音在元、辅音集合中的序号\n",
    "            count+=1\n",
    "            if sub_prons[i][-1] == '1':\n",
    "                stressVowelIndex = count\n",
    "        else:\n",
    "            pronsSeq.append(vowelAndconsonan.index(sub_prons[i])) #取得辅音在元辅、音集合中的序号\n",
    "    return stressVowelIndex, wordLen, count, pronsSeq, vowelsSeq, hasPre, hasEnd\n",
    "\n",
    "#输入测试单词和目标获取：元音数, 音标序列，元音序列, 有无对应前缀，有无对应后缀\n",
    "def getInfoOfPronsFromTest(word, prons):\n",
    "    hasPre = s_has_pre(word)\n",
    "    hasEnd = s_has_end(word)\n",
    "    pronsSeq = []\n",
    "    vowelsSeq = []\n",
    "    count = 0\n",
    "    sub_prons = prons.split(' ')\n",
    "    for i in range(len(sub_prons)):\n",
    "        if sub_prons[i] in vowel:\n",
    "            vowelsSeq.append(vowel.index(sub_prons[i])) #取得元音在元音集合中的序号\n",
    "            count+=1\n",
    "        pronsSeq.append(vowelAndconsonan.index(sub_prons[i])) #取得辅音在元辅、音集合中的序号\n",
    "    return count, pronsSeq, vowelsSeq, hasPre, hasEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "MUSCLING M AH1 S AH0 L IH0 NG\n",
      "1 8 3 [26, 2, 30, 2, 25, 9, 28] [2, 2, 9] 0 1\n",
      "LEARNING L ER N IH NG\n",
      "2 [25, 7, 27, 9, 28] [7, 9] 0 1\n"
     ]
    }
   ],
   "source": [
    "## function test 这里是我上面两个函数的测试\n",
    "a1, a2 = training_data[3].split(':')\n",
    "\n",
    "print(len(a1))\n",
    "\n",
    "print(a1, a2)\n",
    "b1, b2, b3, b4, b5, b6, b7= getInfoOfPronsFromTrain(a1, a2)\n",
    "print(b1, b2, b3, b4, b5, b6, b7)\n",
    "\n",
    "a1, a2 = testing_data[3].split(':')\n",
    "print(a1, a2)\n",
    "b1, b2, b3, b4, b5= getInfoOfPronsFromTest(a1, a2)\n",
    "print(b1, b2, b3, b4, b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetArr = []\n",
    "wordLenArr = []\n",
    "countArr = []\n",
    "pronsSeqArr = [] \n",
    "vowelsSeqArr = []\n",
    "hasPreArr = []\n",
    "hasEndArr = []\n",
    "\n",
    "for i in range(len(training_data)):\n",
    "    t_word, t_prons = training_data[i].split(':')\n",
    "    t1, t2, t3, t4, t5, t6, t7 = getInfoOfPronsFromTrain(t_word, t_prons)\n",
    "    targetArr.append(t1)\n",
    "    wordLenArr.append(t2)\n",
    "    countArr.append(t3)\n",
    "    pronsSeqArr.append(t4) \n",
    "    vowelsSeqArr.append(t5)\n",
    "    hasPreArr.append(t6)\n",
    "    hasEndArr.append(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>data</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>pronsSeq</th>\n",
       "      <th>target</th>\n",
       "      <th>vowelsSeq</th>\n",
       "      <th>wordLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>COED:K OW1 EH2 D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[24, 11, 6, 18]</td>\n",
       "      <td>1</td>\n",
       "      <td>[11, 6]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PURVIEW:P ER1 V Y UW2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 7, 34, 36, 14]</td>\n",
       "      <td>1</td>\n",
       "      <td>[7, 14]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>HEHIR:HH EH1 HH IH0 R</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[22, 6, 22, 9, 29]</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MUSCLING:M AH1 S AH0 L IH0 NG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[26, 2, 30, 2, 25, 9, 28]</td>\n",
       "      <td>1</td>\n",
       "      <td>[2, 2, 9]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NONPOISONOUS:N AA0 N P OY1 Z AH0 N AH0 S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[27, 0, 27, 15, 12, 37, 2, 27, 2, 30]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 12, 2, 2]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                      data  hasEnd  hasPre  \\\n",
       "0      2                          COED:K OW1 EH2 D       1       1   \n",
       "1      2                     PURVIEW:P ER1 V Y UW2       1       1   \n",
       "2      2                     HEHIR:HH EH1 HH IH0 R       1       0   \n",
       "3      3             MUSCLING:M AH1 S AH0 L IH0 NG       1       0   \n",
       "4      4  NONPOISONOUS:N AA0 N P OY1 Z AH0 N AH0 S       1       1   \n",
       "\n",
       "                                pronsSeq  target      vowelsSeq  wordLen  \n",
       "0                        [24, 11, 6, 18]       1        [11, 6]        4  \n",
       "1                    [15, 7, 34, 36, 14]       1        [7, 14]        7  \n",
       "2                     [22, 6, 22, 9, 29]       1         [6, 9]        5  \n",
       "3              [26, 2, 30, 2, 25, 9, 28]       1      [2, 2, 9]        8  \n",
       "4  [27, 0, 27, 15, 12, 37, 2, 27, 2, 30]       2  [0, 12, 2, 2]       12  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'data' : training_data,\n",
    "                   'target' : targetArr,\n",
    "                   'wordLen': wordLenArr,\n",
    "                   'count' : countArr,\n",
    "                   'pronsSeq' : pronsSeqArr,\n",
    "                   'vowelsSeq' : vowelsSeqArr,\n",
    "                   'hasPre' : hasPreArr,\n",
    "                   'hasEnd' : hasEndArr\n",
    "})\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hasEnd</th>\n",
       "      <th>hasPre</th>\n",
       "      <th>target</th>\n",
       "      <th>wordLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.567340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443140</td>\n",
       "      <td>1.364080</td>\n",
       "      <td>7.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.696358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>0.595326</td>\n",
       "      <td>1.879673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count   hasEnd        hasPre        target       wordLen\n",
       "count  50000.000000  50000.0  50000.000000  50000.000000  50000.000000\n",
       "mean       2.567340      1.0      0.443140      1.364080      7.582100\n",
       "std        0.696358      0.0      0.496761      0.595326      1.879673\n",
       "min        2.000000      1.0      0.000000      1.000000      1.000000\n",
       "25%        2.000000      1.0      0.000000      1.000000      6.000000\n",
       "50%        2.000000      1.0      0.000000      1.000000      7.000000\n",
       "75%        3.000000      1.0      1.000000      2.000000      9.000000\n",
       "max        4.000000      1.0      1.000000      4.000000     17.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length in pronsSeq 14\n",
      "max length in vowelsSeq 4\n"
     ]
    }
   ],
   "source": [
    "#看看最长的音标数\n",
    "maxlen = 0\n",
    "for temp_arr in pronsSeqArr:\n",
    "    if len(temp_arr) > maxlen:\n",
    "        maxlen = len(temp_arr)\n",
    "print('max length in pronsSeq', maxlen)\n",
    "\n",
    "##看看最长的元音数\n",
    "maxlen = 0\n",
    "for temp_arr in vowelsSeqArr:\n",
    "    if len(temp_arr) > maxlen:\n",
    "        maxlen = len(temp_arr)\n",
    "print('max length in vowelsSeq', maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 研究发现hasEnd的方差为0，舍去,  同时发现元音长度是一个很好的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['count', 'target']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下是特征矩阵构造\n",
    "0: 只用元音个数\n",
    "\n",
    "1: 元音个数+前缀\n",
    "\n",
    "2: 元音个数+前缀+音节序列\n",
    "\n",
    "3: 元音个数+前缀+元音序列\n",
    "\n",
    "4: 单词长度+元音个数+前缀+元音序列\n",
    "\n",
    "5: 元音个数+元音序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵0\n",
    "labels_0 = []\n",
    "for i in range(len(training_data)):\n",
    "    labels_0.append([countArr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵1\n",
    "labels_1 = []\n",
    "for i in range(len(training_data)):\n",
    "    labels_1.append([countArr[i], hasPreArr[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pronsSeqArr2 = []\n",
    "\n",
    "for temp in pronsSeqArr:\n",
    "    k = 14 - len(temp)\n",
    "    temp += [-1] * k\n",
    "    pronsSeqArr2.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵2\n",
    "labels_2 = []\n",
    "for i in range(len(training_data)):\n",
    "    tempList = [countArr[i], hasPreArr[i]]\n",
    "    tempList += pronsSeqArr2[i];\n",
    "    labels_2.append(tempList)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵3\n",
    "vowelsSeqArr2 = []\n",
    "\n",
    "for temp in vowelsSeqArr:\n",
    "    k = 4 - len(temp)\n",
    "    temp += [-1] * k\n",
    "    vowelsSeqArr2.append(temp)   \n",
    "\n",
    "labels_3 = []\n",
    "for i in range(len(training_data)):\n",
    "    tempList = [countArr[i], hasPreArr[i]]\n",
    "    tempList += vowelsSeqArr2[i];\n",
    "    labels_3.append(tempList) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵4\n",
    "labels_4  = []\n",
    "for i in range(len(training_data)):\n",
    "    tempList = [wordLenArr[i], countArr[i], hasPreArr[i]]\n",
    "    tempList += vowelsSeqArr2[i];\n",
    "    labels_4.append(tempList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造特征矩阵5  \n",
    "\n",
    "labels_5 = []\n",
    "for i in range(len(training_data)):\n",
    "    tempList = [countArr[i]]\n",
    "    tempList += vowelsSeqArr2[i];\n",
    "    labels_5.append(tempList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_2 =  pd.DataFrame(labels_3)\n",
    "df_labels_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data太少，直接用train中的50000个进行交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(labels_3, targetArr, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#使用信息熵作为划分标准，对决策树进行训练\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#系数反映每个特征的影响力。越大表示该特征在分类中起到的作用越大\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = clf.predict(x_train)\n",
    "answer2 = clf.predict(x_test)\n",
    "print(answer)\n",
    "# print(np.mean( answer == y_train))\n",
    "print('f1 for train = ' , f1_score(y_train, answer, average='micro'))\n",
    "print('f1 for test = ' , f1_score(y_test, answer2, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "test_mean = []\n",
    "\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(labels_5, targetArr, test_size = 0.2) \n",
    "    #使用信息熵作为划分标准，对决策树进行训练\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "    clf.fit(x_train, y_train)\n",
    "    answer = clf.predict(x_train)\n",
    "    answer2 = clf.predict(x_test)\n",
    "    f1_train = f1_score(y_train, answer, average='micro')\n",
    "    f1_test = f1_score(y_test, answer2, average='micro')\n",
    "    \n",
    "    test_mean.append(f1_test)\n",
    "\n",
    "# print('f1 for train = ' , f1_score(y_train, answer, average='micro'))\n",
    "# print('f1 for test = ' , f1_score(y_test, answer2, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这里是试验田\n",
    "import numpy\n",
    "len(test_mean)\n",
    "\n",
    "narray = numpy.array(test_mean)\n",
    "\n",
    "narray.sum() / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf_bayes = linear_model.BayesianRidge()\n",
    "clf_bayes.fit(x_train, y_train)\n",
    "answer = clf_bayes.predict(x_train).round() #取整\n",
    "answer2 = clf_bayes.predict(x_test).round()\n",
    "print('f1 for train = ' , f1_score(y_train, answer, average='micro'))\n",
    "print('f1 for test = ' , f1_score(y_test, answer2, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 聚类方法的研究\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster   import KMeans \n",
    "#使用默认的K-Means算法  \n",
    "num_clusters = 4\n",
    "kmeans_clf = KMeans(n_clusters=num_clusters)  \n",
    "kmeans_clf.fit(x_train)  \n",
    "print(kmeans_clf.labels_) \n",
    "\n",
    "answer = kmeans_clf.predict(x_train)\n",
    "answer2 = kmeans_clf.predict(x_test)\n",
    "print('f1 for train = ' , f1_score(y_train, answer, average='micro'))\n",
    "print('f1 for test = ' , f1_score(y_test, answer2, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
